<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>spark on Halface</title>
    <link>https://h4lf4c3.github.io/categories/spark/</link>
    <description>Recent content in spark on Halface</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Wed, 09 Sep 2020 13:58:04 +0800</lastBuildDate><atom:link href="https://h4lf4c3.github.io/categories/spark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Spark二次排序笔记</title>
      <link>https://h4lf4c3.github.io/post/spark%E4%BA%8C%E6%AC%A1%E6%8E%92%E5%BA%8F%E7%AC%94%E8%AE%B0/</link>
      <pubDate>Wed, 09 Sep 2020 13:58:04 +0800</pubDate>
      
      <guid>https://h4lf4c3.github.io/post/spark%E4%BA%8C%E6%AC%A1%E6%8E%92%E5%BA%8F%E7%AC%94%E8%AE%B0/</guid>
      <description>Spark二次排序笔记 引言 让我们先思考一下什么是二次排序，这是一个很典型的数据处理算法。首先我们有一个数据，这个数据的key之间是有序的，而</description>
    </item>
    
    <item>
      <title>spark中的aggregate函数</title>
      <link>https://h4lf4c3.github.io/post/spark%E4%B8%AD%E7%9A%84aggregate%E5%87%BD%E6%95%B0/</link>
      <pubDate>Thu, 14 May 2020 10:53:55 +0000</pubDate>
      
      <guid>https://h4lf4c3.github.io/post/spark%E4%B8%AD%E7%9A%84aggregate%E5%87%BD%E6%95%B0/</guid>
      <description>&lt;h1 id=&#34;spark中的aggregate函数&#34;&gt;spark中的aggregate函数&lt;/h1&gt;
&lt;p&gt;学习到spark的RDD行动操作时，有一个函数可让我废了半天脑筋，就是aggregate函数，aggregate的意思是&lt;strong&gt;聚合&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;我们首先来看一下spark官方文档对这一函数的说明：&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>spark示例遇到的一个坑</title>
      <link>https://h4lf4c3.github.io/post/idea%E8%BF%9C%E7%A8%8B%E6%8F%90%E4%BA%A4spark%E7%A4%BA%E4%BE%8B%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%B8%AA%E5%9D%91/</link>
      <pubDate>Tue, 12 May 2020 08:37:49 +0000</pubDate>
      
      <guid>https://h4lf4c3.github.io/post/idea%E8%BF%9C%E7%A8%8B%E6%8F%90%E4%BA%A4spark%E7%A4%BA%E4%BE%8B%E9%81%87%E5%88%B0%E7%9A%84%E4%B8%80%E4%B8%AA%E5%9D%91/</guid>
      <description>&lt;h1 id=&#34;idea远程提交spark示例遇到的一个坑&#34;&gt;IDEA远程提交spark示例遇到的一个坑&lt;/h1&gt;
&lt;p&gt;先前使用idea进行远程提交spark程序采用的是local，也就相当于单机版spark，于是乎我又试了一下spark自带的standalone模式。但是在setMaster(&amp;ldquo;spark://192.168.160.30:7077&amp;rdquo;)的时候出现了问题&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>spark&#43;IDEA示例</title>
      <link>https://h4lf4c3.github.io/post/spark&#43;idea%E7%A4%BA%E4%BE%8B/</link>
      <pubDate>Fri, 17 Apr 2020 10:03:33 +0000</pubDate>
      
      <guid>https://h4lf4c3.github.io/post/spark&#43;idea%E7%A4%BA%E4%BE%8B/</guid>
      <description>&lt;h1 id=&#34;sparkidea示例&#34;&gt;spark+IDEA示例&lt;/h1&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34;&gt;1
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;2
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;3
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;4
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;5
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;6
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;7
&lt;/span&gt;&lt;span class=&#34;lnt&#34;&gt;8
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;集群
master 192.168.160.21
slave1 192.168.160.22
slave2 192.168.160.23
这里用的安装包版本为
scala-2.11.8.tgz
spark-2.1.3-bin-hadoop2.7.tgz
spark安装包的选择根据你的hadoop和scala版本来，官网有详细说明
&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>
